{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "GYK5qpW325qk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = r'shakespeare.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DINcX0xL20vG",
    "outputId": "4fbdb9e9-6046-4761-d2f6-be24c992dd50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uugzs2fU23M7",
    "outputId": "b6e8cca7-4aeb-4996-fc3c-be92880cfdf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it \n"
     ]
    }
   ],
   "source": [
    "print(text[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "p_y8K_Vd2_qz"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = \"cuda:0\"\n",
    "else:\n",
    "  device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "iVPNsTzk3ibh"
   },
   "outputs": [],
   "source": [
    "vocab = set(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "9C6t2HDA3JZB"
   },
   "outputs": [],
   "source": [
    "char2idx = {ch:i for i,ch in enumerate(vocab)}\n",
    "idx2char = {i:ch for i,ch in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "V_G8fXVo3SfV"
   },
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, output_size):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.output_size = output_size\n",
    "    self.embedding = nn.Embedding(input_size, input_size)\n",
    "    self.rnn = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=2)\n",
    "    self.decoder = nn.Linear(hidden_size, output_size)\n",
    "  def forward(self, x, hidden):\n",
    "    embedding = self.embedding(x)\n",
    "    outputs, h_n = self.rnn(embedding, hidden)\n",
    "    outputs = self.decoder(outputs)\n",
    "    return outputs, h_n.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "64F15ceC3vqG"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "hidden_size = 512\n",
    "learning_rate = 0.0001\n",
    "input_size = vocab_size\n",
    "output_size = vocab_size\n",
    "seq_length = 100\n",
    "text_size = len(text)\n",
    "EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "tVtSfJ8iBI9Y"
   },
   "outputs": [],
   "source": [
    "inputs = [char2idx[i] for i in text[:seq_length]]\n",
    "outputs = [char2idx[i] for i in text[1:seq_length+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I1z6r95XDPfp",
    "outputId": "f6a5004a-1764-4d3d-ef56-6a7effa35d14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1115394, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_text = [char2idx[i] for i in text]\n",
    "enc_text = torch.tensor(enc_text).long().to(device)\n",
    "enc_text.unsqueeze_(1)\n",
    "enc_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MYlDC0AZBW87",
    "outputId": "a63ad456-6182-4d13-fd01-7f9f0fccc2b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = enc_text[:seq_length]\n",
    "# inputs = inputs.unsqueeze(1)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oajqOlzKECd0"
   },
   "outputs": [],
   "source": [
    "model = MyModel(input_size, hidden_size, output_size).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0tz32UoBCjBV",
    "outputId": "a6fc8c70-3b95-4277-a5bb-fe252299a6c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 1 Epoch_loss : 1.376428\n",
      "thy,\n",
      "Unsure gentlemony toward last cause,\n",
      "Should feable again'd gave time it a strepl\n",
      "To our weets, fouches the dwelter minuble and\n",
      "The lightsable. When, trelow,\n",
      "The unlikent after men! hear, kemire,\n",
      "W\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 2 Epoch_loss : 1.308181\n",
      "ozQ\n",
      "AN wise, was a words perfactionloban!\n",
      "\n",
      "ANTONIO:\n",
      "No, sir, my widowing.\n",
      "\n",
      "Lard Katharine:\n",
      "Is tending the biek of wancentate,\n",
      "Than old has a little dlumbering frem it.\n",
      "\n",
      "GONZALO:\n",
      "So, in Byich, Good Trum\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 3 Epoch_loss : 1.260548\n",
      "ent.\n",
      "\n",
      "ALONSO:\n",
      "What was not she hath like; fie, thou hast vent there weak;\n",
      "now, pristress in youry-qound entreater, both the death:\n",
      "Who would be dolination build thy lights be blind.\n",
      "\n",
      "MENENIUS:\n",
      "Nothing \n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 4 Epoch_loss : 1.222941\n",
      "rUTy Verunam\n",
      "The debt not all of gentleman, not,--\n",
      "\n",
      "ANTONIO:\n",
      "Lambing it office!\n",
      "\n",
      "VOLANDAN:\n",
      "I ax as.\n",
      "\n",
      "GONZALO:\n",
      "No! is the point at our son?\n",
      "\n",
      "TRANIO:\n",
      "Ah, growing me, then every rubbright sister,\n",
      "Have not\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 5 Epoch_loss : 1.190519\n",
      "high.\n",
      "So, softly, all, to bed, and his watch.\n",
      "What, not who\n",
      "nottess of nine, of your star before;\n",
      "Whither! Wife, as virtue: peace, foolion, gamp!\n",
      "On fortune! I am quicks, carried forth,\n",
      "As thou art new\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 6 Epoch_loss : 1.161028\n",
      "ford:\n",
      "The lord is mible, and of a state.\n",
      "\n",
      "CULIO:\n",
      "Sir, drawndly, Castiance.\n",
      "\n",
      "GONZALO:\n",
      "We will comfort to these hour of bravely?\n",
      "\n",
      "DETRONSE:\n",
      "Who,\n",
      "Woetly! take questious take it escape.\n",
      "\n",
      "GROMIO:\n",
      "Yes, bost \n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 7 Epoch_loss : 1.133368\n",
      " izzize!\n",
      "\n",
      "VINCENTIO:\n",
      "The acclitable son of Saint Greater, with soldier,\n",
      "makest thou often next creature; by my father's bones\n",
      "Will be satisfaction, of Napilia couraa,\n",
      "Whose gentlewoman was a tracious.\n",
      "\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 8 Epoch_loss : 1.106398\n",
      "ant:\n",
      "Would he came a tribe,\n",
      "Allawing the faminack; we come for the very\n",
      "tences preservello. Sir,\n",
      "how I had; not you all first our livest!\n",
      "\n",
      "LUCENTIO:\n",
      "Sir, we may.\n",
      "\n",
      "GONZALO:\n",
      "The soul--fool, command winte\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 9 Epoch_loss : 1.079535\n",
      "lIZAO:\n",
      "Where foul safety, to Bnaunto's to the tongue.\n",
      "\n",
      "Boatstane:\n",
      "And thou shalt thou ne!\n",
      "\n",
      "MIRANDA:\n",
      "O, belike, fellow.\n",
      "\n",
      "GONZALO:\n",
      "Go, Warwick, kiss't; son ower to speak,\n",
      "To speak vileniven'd beauty eart\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 10 Epoch_loss : 1.052670\n",
      "odds:\n",
      "Within this state, father!\n",
      "\n",
      "GONZALO:\n",
      "Something never make hare you up.\n",
      "\n",
      "ANTONIO:\n",
      "Dedicita thy kindness know't;\n",
      "His name is sweet mercy; serve, 'tis learn.\n",
      "\n",
      "SEBASTIAN:\n",
      "So far fall\n",
      "Is feeding-darke\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 11 Epoch_loss : 1.025749\n",
      " Frost:\n",
      "'Tis time was a going: then I'll rancon was but\n",
      "neather, give me pack.\n",
      "\n",
      "LUCENTIO:\n",
      "You would not satisfy your own injurions\n",
      "That thou'rt and all in seconded danciness\n",
      "Wither, thou carringer-stor\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 12 Epoch_loss : 0.998562\n",
      "ant:\n",
      "Indeed, unvirgue. Thy sleet, wise men news.\n",
      "\n",
      "SEBASTIAN:\n",
      "Not a warranted with broken fright thee or\n",
      "In sogether.\n",
      "\n",
      "GONZALO:\n",
      "It crap out quakes all the last.\n",
      "\n",
      "PROSPERO:\n",
      "By pursuing soul upon I, none,\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 13 Epoch_loss : 0.971206\n",
      "twh:\n",
      "The whits welcome.\n",
      "\n",
      "ALONSO:\n",
      "My mind is lost innocent.\n",
      "\n",
      "SEBASTIAN:\n",
      "Carryon, though they cave for, howny o' the sea\n",
      "And damnat-place; or what a fever stand\n",
      "her eye, all afored out air.\n",
      "\n",
      "VALERIA:\n",
      "You\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 14 Epoch_loss : 0.943939\n",
      "\n",
      "Wart our glifes? are word the ship or elecast,\n",
      "Marking he flamentation oper when it was\n",
      "A poor worked in merrieling hours or else:\n",
      "Give we sworn your engrible: for Capito was his\n",
      "Trespassing this cowa\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 15 Epoch_loss : 0.916912\n",
      "und:\n",
      "Away with your safety! Thou know'st, not struck\n",
      "And glant, I pray you, sir.\n",
      "\n",
      "LUCEN SpARI\n",
      "AEdile; contrary day, sir!\n",
      "\n",
      "ALONSO:\n",
      "Well, then starve-like to see thy weapons.\n",
      "\n",
      "GONZALO:\n",
      "Ay, and already by\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "# LEARNING RATE = 0.0005\n",
    "import numpy as np\n",
    "for epoch in range(EPOCHS):\n",
    "  p = 0\n",
    "  seq_len = seq_length\n",
    "  total_loss = 0\n",
    "  hidden = None\n",
    "  cnt = 0\n",
    "  while p+seq_len+1 < text_size:\n",
    "    inputs = enc_text[p:p+seq_length]\n",
    "    targets = enc_text[p+1:p+seq_length+1]\n",
    "    outputs, hidden = model(inputs, hidden)\n",
    "    loss = loss_fn(torch.squeeze(outputs), torch.squeeze(targets))\n",
    "    total_loss += loss.item()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    cnt += 1\n",
    "    p += seq_length\n",
    "    if cnt % 500 == 0:\n",
    "      print('|',end='')\n",
    "  print('\\n--------------------------')\n",
    "      # print(\"Cnt : {} Loss : {:5f}\".format(cnt, total_loss/cnt))\n",
    "  print(\"Epoch : {} Epoch_loss : {:5f}\".format(epoch+1, total_loss/cnt))\n",
    "  total_loss = 0\n",
    "  cnt = 0\n",
    "  with torch.no_grad():\n",
    "    rand_index = np.random.randint(text_size-1)\n",
    "    input_seq = enc_text[rand_index:rand_index+1]\n",
    "    print(idx2char[input_seq[0][0].item()], end='')\n",
    "    hidden = None\n",
    "    size = 0\n",
    "    while size < 200:\n",
    "      outputs, hidden = model(input_seq, hidden)\n",
    "      outputs = F.softmax(torch.squeeze(outputs), dim=0)\n",
    "      dist = Categorical(outputs)\n",
    "      index = dist.sample()\n",
    "      # input_seq[0][0] = index.item()\n",
    "      input_seq[0][0] = index.item()\n",
    "      # input = input.unsqueeze(0)\n",
    "      print(idx2char[index.item()], end='')\n",
    "      size += 1\n",
    "    print(\"\\n-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQCnBVSuLk_r",
    "outputId": "655aafd0-ec50-4ca4-e9ab-3b1f152987a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 1 Epoch_loss : 0.890426\n",
      "NGEL:\n",
      "To-morrow.\n",
      "\n",
      "ANTONIO:\n",
      "Why thence pitch--home?\n",
      "\n",
      "GONZALO:\n",
      "It is foul postern built what I bones on me;\n",
      "Nay, if thou fond pursues truly.\n",
      "\n",
      "VINCENTIO:\n",
      "Content thee.\n",
      "\n",
      "GONZALO:\n",
      "Who in love of is?\n",
      "\n",
      "ANTONIO:\n",
      "Stop the harvest freek, on Thomas that worthy spent\n",
      "Is mock'd with a little; and would say, if st\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 2 Epoch_loss : 0.864858\n",
      "ike:\n",
      "He dropp'd upon my state, not again.\n",
      "\n",
      "HORTENSIO:\n",
      "Come; I fear the storm. Would I make money?\n",
      "\n",
      "ANTONIO:\n",
      "Faith, dear madam.\n",
      "\n",
      "GONZALO:\n",
      "It was against us.\n",
      "\n",
      "GONZALO:\n",
      "And she have both entreat me horse; on my hand\n",
      "In sweet wagunation. I\n",
      "affer this wide of more kind\n",
      "In your instructions for Angelo;\n",
      "I m\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 3 Epoch_loss : 0.839790\n",
      "t,\n",
      "O, I am put time to cross to soo!\n",
      "So fain!\n",
      "\n",
      "SEBASTIAN:\n",
      "Why, away, toward Signior Baptista.\n",
      "\n",
      "GONZALO:\n",
      "'Tis wondrous maid:\n",
      "I part me not.\n",
      "\n",
      "GONZALO:\n",
      "When I am bound ere now down for this\n",
      "That his post thy image,\n",
      "Home-boldly.\n",
      "\n",
      "SEBASTIAN:\n",
      "But when I do bid the cause of trick\n",
      "and never thinks the loss o\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 4 Epoch_loss : 0.816207\n",
      " VINGERe\n",
      "My sigh, the next nuns of fenious life,\n",
      "And gine out o' the less, and now come back again.\n",
      "There were not fours attend to't, sir,\n",
      "How is it brought to instruct them all,\n",
      "That wilt have born to any revenge, each nothing\n",
      "When men never been in't, all so you should\n",
      "tapsters, father.\n",
      "\n",
      "PROSPERO:\n",
      "\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 5 Epoch_loss : 0.794097\n",
      "IZ!\n",
      "Sweet son, Petruchio,--\n",
      "\n",
      "SEBBID:\n",
      "Sir, look down with us.\n",
      "\n",
      "ANTONIO:\n",
      "One word more; I had at nose it now\n",
      "Do assist you, unknown to know the senators,\n",
      "Sufficient in his daughter, and, in prying his ear;\n",
      "One of thyself writ her and will not\n",
      "have forth not to commanded: I do not stay\n",
      "Call forth works \n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 6 Epoch_loss : 0.772706\n",
      " VINCENTI Oxford!\n",
      "\n",
      "GONZALO:\n",
      "If thou kern good prayers.\n",
      "\n",
      "ANTONIO:\n",
      "And who should so well believe a bear.\n",
      "\n",
      "ALONSO:\n",
      "Please the trade of heart\n",
      "My mind perfugies undone.\n",
      "\n",
      "ANTONIO:\n",
      "He dost infect his soul silence on Thomas\n",
      "Of wheeps netter heard of my service.\n",
      "\n",
      "ANTONIO:\n",
      "No.\n",
      "\n",
      "SEBASTIAN:\n",
      "She lies,\n",
      "made, yet \n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 7 Epoch_loss : 0.752907\n",
      " VINCENTI OF York:\n",
      "And you are well: now, my master will come on;\n",
      "This sensible piece it was, the preception\n",
      "Who in this distress o' the usiner.\n",
      "\n",
      "SEBASTIAN:\n",
      "God save this, you qualk, Title, calumny and\n",
      "The Volsces may forbid!\n",
      "\n",
      "LASTISS:\n",
      "Too good father,\n",
      "Task you word or thou to Anny\n",
      "Wouldst bear so mu\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 8 Epoch_loss : 0.734704\n",
      "ond:\n",
      "Now is the death, and brave me a slave, I would\n",
      "his conceal with slander-seeth with us and pluck\n",
      "The envious love!\n",
      "\n",
      "SEBASTIAN:\n",
      "Look the lustitution of it?\n",
      "\n",
      "ANTONIO:\n",
      "I bore him with be;\n",
      "And, by embrace with old father is as\n",
      "sin to your ways, I worous poor subsion\n",
      "That seit their denials bows: but\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 9 Epoch_loss : 0.717435\n",
      ":\n",
      "Nay, if you will succeed with note as mine,\n",
      "And thou speak'st not straight\n",
      "You'll lie in feet o'erward, when you\n",
      "shall command.\n",
      "\n",
      "OnfO:\n",
      "She was not one such comfort, sir! nay, where\n",
      "any thing the whicted friends, nor this way,\n",
      "It is a sailor'd 'phar's eye.\n",
      "\n",
      "FERDINAND:\n",
      "No;\n",
      "I know not here.\n",
      "\n",
      "ANTONIO:\n",
      "\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 10 Epoch_loss : 0.701516\n",
      "hy:\n",
      "Who know'st\n",
      "thou to the gown; exhal I die.\n",
      "\n",
      "GONZALO:\n",
      "Wooth, he is a school! away with one one\n",
      "On the garlands be confit'd my hearts\n",
      "As we shall ha' meat to think within the velves.\n",
      "My father was the slave of the northern cloging\n",
      "inch so long obstinencan so ill-boy, in thieves;\n",
      "Or witcher, my mast\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 11 Epoch_loss : 0.685663\n",
      "ride:\n",
      "I am the face of orcagua,\n",
      "Come all their goodness.\n",
      "\n",
      "SEBASTIAN:\n",
      "O how I speak so assurance.\n",
      "\n",
      "LUCENTIO:\n",
      "\n",
      "All:\n",
      "Content, that was my son being that makes of her\n",
      "That which is index far indifferent sleep,\n",
      "Until my succeed wrong, clamour to these wooers.\n",
      "Thou following sleep, this is no worse than sl\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 12 Epoch_loss : 0.671686\n",
      "dry:\n",
      "'That was he the gods of Milan,--What makes you so?\n",
      "\n",
      "SEBASTIAN:\n",
      "Do't work we mean on him that hard my heart\n",
      "Makes! I think she might show you my master;\n",
      "And by his son you thence, Grumis,\n",
      "Who woo'd their waits of night; and when thou art,\n",
      "Without loss of silken outrage, Caliban\n",
      "Your lustful mean\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 13 Epoch_loss : 0.658899\n",
      "esse:\n",
      "Inkin's thine, and he holp to see thy spirit\n",
      "Which thou says her own confederatessment\n",
      "With oath on edges undoned again.\n",
      "\n",
      "SEBASTIAN:\n",
      "Go honourable time to pity.\n",
      "\n",
      "ANTONIO:\n",
      "Wouldst thank your worship in good success!\n",
      "\n",
      "GONZALO:\n",
      "Not so, and sit for state.\n",
      "\n",
      "ANTONIO:\n",
      "I fear me, have made good to them\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 14 Epoch_loss : 0.645683\n",
      " VINCENTI OF YORK:\n",
      "I thank you, sir, well I must not.\n",
      "\n",
      "ANTONIO:\n",
      "We have not piteon with never to seal'd,\n",
      "Some of the earth or intertaining arts,\n",
      "My house and langing gently years\n",
      "Whereof,\n",
      "More holp to speak, good Lidio's bone;\n",
      "An yet no man, breeds nor no marm new-right:\n",
      "What, would the key, and beli\n",
      "-----------------------\n",
      "||||||||||||||||||||||\n",
      "--------------------------\n",
      "Epoch : 15 Epoch_loss : 0.634705\n",
      " hint:\n",
      "Rivers, Signior Gremio, Welmsham know'st,\n",
      "That kindling care wager forth. But indeed I\n",
      "spake it on you: let it corrupt or shame and boot\n",
      "Which seem to chat with your duty. Sild, peace;\n",
      "Thou shouldst repeased by him; for he,\n",
      "That nothing lurk'd o' the eyes of mine, which spake\n",
      "With honey well a\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "#LEARNING RATE = 0.0001\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  p = 0\n",
    "  seq_len = seq_length\n",
    "  total_loss = 0\n",
    "  hidden = None\n",
    "  cnt = 0\n",
    "  while p+seq_len+1 < text_size:\n",
    "    inputs = enc_text[p:p+seq_length]\n",
    "    targets = enc_text[p+1:p+seq_length+1]\n",
    "    outputs, hidden = model(inputs, hidden)\n",
    "    loss = loss_fn(torch.squeeze(outputs), torch.squeeze(targets))\n",
    "    total_loss += loss.item()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    cnt += 1\n",
    "    p += seq_length\n",
    "    if cnt % 500 == 0:\n",
    "      print('|',end='')\n",
    "  print('\\n--------------------------')\n",
    "      # print(\"Cnt : {} Loss : {:5f}\".format(cnt, total_loss/cnt))\n",
    "  print(\"Epoch : {} Epoch_loss : {:5f}\".format(epoch+1, total_loss/cnt))\n",
    "  total_loss = 0\n",
    "  cnt = 0\n",
    "  with torch.no_grad():\n",
    "    rand_index = np.random.randint(text_size-1)\n",
    "    input_seq = enc_text[rand_index:rand_index+1]\n",
    "    print(idx2char[input_seq[0][0].item()], end='')\n",
    "    hidden = None\n",
    "    size = 0\n",
    "    while size < 300:\n",
    "      outputs, hidden = model(input_seq, hidden)\n",
    "      outputs = F.softmax(torch.squeeze(outputs), dim=0)\n",
    "      dist = Categorical(outputs)\n",
    "      index = dist.sample()\n",
    "      # input_seq[0][0] = index.item()\n",
    "      input_seq[0][0] = index.item()\n",
    "      # input = input.unsqueeze(0)\n",
    "      print(idx2char[index.item()], end='')\n",
    "      size += 1\n",
    "    print(\"\\n-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WyvazoxCkvrs",
    "outputId": "a41e8bec-0838-4c60-8821-2dd4114e1642"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eds:\n",
      "That Claudio, Signior Capitoo,\n",
      "Whom I ever sent for shame; for I have spoke,\n",
      "To be thy need to make them obeys, good daughter!\n",
      "O, how peaches it to do so! My father hath\n",
      "stay; the frosting fury seal o' the sister.\n",
      "\n",
      "COMINIUS:\n",
      "Hear me, my drink.\n",
      "\n",
      "SEBASTIAN:\n",
      "Sir, but he's for the fight!\n",
      "\n",
      "PETRUCHIO:\n",
      "Go far on; marry, speak take, and then go with me;\n",
      "Nor I am coming that you made, my life\n",
      "Uncur to choose away our neck orderers;\n",
      "The false Binnot dry your eye, but indeed\n",
      "Name hath stifl us.\n",
      "\n",
      "ADRIAN:\n",
      "And most comfort's.\n",
      "\n",
      "ANTONIO:\n",
      "Not possible.\n",
      "\n",
      "Boatswain:\n",
      "Would I make mercy my sister with honey-gabse-winged\n",
      "what when it would contrary at thy abject son.\n",
      "\n",
      "GONZALO:\n",
      "I would be very wrong, you think.\n",
      "\n",
      "OnOLUME:\n",
      "Should by this shame.\n",
      "How now! what makes you?\n",
      "\n",
      "ARIEL:\n",
      "So long as violent for Tranio in \n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "cnt = 0\n",
    "with torch.no_grad():\n",
    "  rand_index = np.random.randint(text_size-1)\n",
    "  input_seq = enc_text[rand_index:rand_index+1]\n",
    "  print(idx2char[input_seq[0][0].item()], end='')\n",
    "  hidden = None\n",
    "  size = 0\n",
    "  while size < 800:\n",
    "    outputs, hidden = model(input_seq, hidden)\n",
    "    outputs = F.softmax(torch.squeeze(outputs), dim=0)\n",
    "    dist = Categorical(outputs)\n",
    "    index = dist.sample()\n",
    "    # input_seq[0][0] = index.item()\n",
    "    input_seq[0][0] = index.item()\n",
    "    # input = input.unsqueeze(0)\n",
    "    print(idx2char[index.item()], end='')\n",
    "    size += 1\n",
    "  print(\"\\n-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "    torch.save(model.state_dict(), 'model.pt') "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CustomLayers",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0ac574da8a43be42701b79fadd70a2d7159aad5ccc972cab44083488cf25884a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
